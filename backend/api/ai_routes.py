# backend/api/ai_routes.py - æ–‡æª”ç®¡ç† API è·¯ç”±ï¼ˆå«ï¼šé‡å»ºå‘é‡åº« / åˆ†é ï¼‰
from fastapi import APIRouter, HTTPException, UploadFile, File, Form, Depends, Request
from fastapi.responses import FileResponse, JSONResponse
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import logging
import os
import tempfile
from pathlib import Path

from services.ai_service import (
    ai_engine,
    DOCUMENT_CATEGORIES,      # å…è¨±çš„æ–‡ä»¶é¡åˆ¥ï¼ˆç”±æœå‹™å±¤ç¶­è­·ï¼‰
    SUPPORTED_EXTENSIONS,     # æ”¯æ´å‰¯æª”åï¼ˆ.pdf/.docx/...ï¼‰
    DEFAULT_OLLAMA_MODEL,     # é è¨­æœ¬åœ° LLMï¼ˆOllamaï¼‰
)
from core.deps import require_roles, get_current_user

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/ai", tags=["AI Document Analytics"])


# ============================== Pydantic æ¨¡å‹ ==============================
class QueryRequest(BaseModel):
    """
    æ–‡æª”æŸ¥è©¢è«‹æ±‚ï¼š
      - question: æŸ¥è©¢å•é¡Œ
      - use_openai: True æ™‚æ”¹ç”¨é›²ç«¯ OpenAIï¼›False èµ°æœ¬åœ° Ollama
      - openai_model: ä½¿ç”¨çš„ OpenAI æ¨¡å‹ï¼ˆåƒ… use_openai=True æ™‚æœ‰ç”¨ï¼‰
    """
    question: str
    use_openai: bool = False
    openai_model: str = "gpt-4o-mini"


class DocumentResponse(BaseModel):
    """
    æ–‡æª”åˆ—è¡¨å›å‚³é …ï¼ˆåƒ…åŸºç¤æ¬„ä½ï¼›ä¸å«å…¨æ–‡ï¼‰
    - æ³¨æ„ï¼šé€™å€‹æ¨¡å‹å°æ‡‰ ai_engine.get_documents() å›å‚³çš„è³‡æ–™æ ¼å¼
    """
    id: int
    filename: str
    original_name: str
    category: str
    file_type: str
    file_size: int
    content_preview: str
    upload_date: str
    uploaded_by: str
    tags: Optional[str] = ""
    description: Optional[str] = ""


# ============================== å°å·¥å…· ==============================
def _username(user: Any) -> str:
    """
    å¾ user ç‰©ä»¶æˆ– dict å– usernameã€‚
    - FastAPI çš„ dependency æœ‰æ™‚æ˜¯ç‰©ä»¶ï¼ˆ.usernameï¼‰ï¼Œæœ‰æ™‚æ˜¯ dictï¼ˆ["username"]ï¼‰
    - è‹¥å…©è€…çš†ç„¡ â†’ ä»¥ 'unknown' é€€å›ï¼Œé¿å… None æ“¾å‹• DB
    """
    return getattr(user, "username", None) or user.get("username", "unknown")


# =============================================================================
# ç³»çµ±ç‹€æ…‹å’Œä¿¡æ¯
# =============================================================================
@router.get("/status")
async def get_ai_status():
    """
    å–å¾— AI å­ç³»çµ±ç‹€æ…‹ï¼ˆå®Œæ•´åŸå§‹å€¼ï¼‰
    - ä¸»è¦çµ¦ç®¡ç†ç«¯/ç›£æ§é¢æ¿æŸ¥é–±
    """
    try:
        return ai_engine.get_system_status()
    except Exception as e:
        logger.error(f"Error getting AI status: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/categories")
async def get_document_categories():
    """å›å‚³å¯ç”¨æ–‡æª”é¡åˆ¥æ¸…å–®ï¼ˆç”±æœå‹™å±¤é›†ä¸­ç®¡ç†ï¼‰"""
    return {"categories": DOCUMENT_CATEGORIES}


@router.get("/health")
async def ai_health_check():
    """
    å¥åº·æª¢æŸ¥ï¼ˆæä¾›æ‘˜è¦/æ——æ¨™ï¼‰ï¼š
      - status: ready/degraded
      - vector_store_ready: å‘é‡ç´¢å¼•æ˜¯å¦å°±ç·’ï¼ˆRAG å¯ç”¨ï¼‰
      - rag_mode/hyde/compression/parent_feature: æ–¹ä¾¿å‰ç«¯æ±ºç­–æˆ–ç›£æ§
    """
    try:
        status = ai_engine.get_system_status()
        return {
            "service": "ai-document-analytics",
            "status": "healthy" if status.get("status") == "ready" else "degraded",
            "total_documents": status.get("total_documents", 0),
            "vector_store_ready": status.get("vector_store_ready", False),
            "ollama_model": status.get("ollama_model", DEFAULT_OLLAMA_MODEL),
            "openai_available": status.get("openai_available", False),
            # RAG é…ç½®é€å‡ºï¼ˆdebug/å‘Šè­¦/AB æ¸¬è©¦æ–¹ä¾¿ï¼‰
            "rag_mode": status.get("rag_mode"),
            "hyde": status.get("hyde"),
            "compression": status.get("compression"),
            "parent_feature": status.get("parent_feature"),
            "success": True,
        }
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        raise HTTPException(status_code=503, detail="AI service unhealthy")


# =============================================================================
# æ–‡æª”ç®¡ç† (éœ€è¦ç®¡ç†å“¡æ¬Šé™)
# =============================================================================
@router.post("/documents/upload")
async def upload_document(
    file: UploadFile = File(...),
    category: str = Form(...),
    tags: str = Form(""),
    description: str = Form(""),
    current_user: dict = Depends(require_roles("admin")),
):
    """
    ä¸Šå‚³æ–‡æª”ï¼ˆåƒ…ç®¡ç†å“¡ï¼‰
    - ä»¥ä¸²æµå¯«å…¥è‡¨æ™‚æª”ï¼Œé¿å…ä¸€æ¬¡æ€§è®€å¤§æª”ï¼ˆ>50MBï¼‰é€ æˆè¨˜æ†¶é«”å°–å³°
    - é©—è­‰å‰¯æª”åèˆ‡åˆ†é¡ï¼›æª”æ¡ˆå¤§å°è¶…éé™åˆ¶æœƒç«‹å³ä¸­æ­¢
    - ä¸Šå‚³æˆåŠŸå¾Œç§»äº¤ ai_engine è§£æ/å…¥åº«/åˆ‡å¡Š
    """
    MAX_BYTES = 50 * 1024 * 1024  # 50MB
    try:
        # 1) æª¢æŸ¥å‰¯æª”åç™½åå–®
        file_extension = Path(file.filename).suffix.lower()
        if file_extension not in SUPPORTED_EXTENSIONS:
            raise HTTPException(
                status_code=400,
                detail=f"Unsupported file type: {file_extension}. "
                       f"Supported types: {', '.join(sorted(SUPPORTED_EXTENSIONS))}",
            )

        # 2) æª¢æŸ¥é¡åˆ¥æ˜¯å¦æœ‰æ•ˆ
        if category not in DOCUMENT_CATEGORIES:
            raise HTTPException(
                status_code=400,
                detail=f"Invalid category. Valid: {', '.join(DOCUMENT_CATEGORIES.keys())}",
            )

        # 3) ä¸²æµå¯«å…¥è‡¨æ™‚æª”ï¼›é‚Šå¯«é‚Šè¨ˆæ•¸ï¼ˆé¿å… DOS å‹å¤§æª”ï¼‰
        total = 0
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as tmp:
            temp_file_path = tmp.name
            while True:
                chunk = await file.read(1024 * 1024)  # æ¯æ¬¡è®€ 1MB
                if not chunk:
                    break
                total += len(chunk)
                if total > MAX_BYTES:
                    raise HTTPException(status_code=400, detail="File size exceeds 50MB limit")
                tmp.write(chunk)

        # 4) äº¤çµ¦æœå‹™å±¤è™•ç†ï¼ˆæŠ½å–æ–‡å­—ã€åˆ‡åˆ† chunkã€å…¥åº«èˆ‡å‘é‡åŒ–ï¼‰
        try:
            result = ai_engine.upload_document(
                file_path=temp_file_path,
                original_name=file.filename,
                category=category,
                uploaded_by=_username(current_user),
                tags=tags,
                description=description,
            )
            if not result.get("success"):
                # ä¿ç•™æœå‹™å±¤éŒ¯èª¤è¨Šæ¯ï¼Œä¾¿æ–¼å®šä½ï¼ˆæ¬Šé™/è§£æ/OCR ç­‰ï¼‰
                raise HTTPException(status_code=400, detail=result.get("error", "Upload failed"))

            logger.info(f"âœ… Document uploaded by {_username(current_user)}: {file.filename}")
            return {
                "success": True,
                "message": "Document uploaded successfully",
                "document_id": result["document_id"],
                "filename": result["filename"],
                "content_length": result["content_length"],
                "chunks_created": result["chunks_created"],
            }
        finally:
            # 5) ä¸è«–æˆåŠŸ/å¤±æ•—éƒ½å˜—è©¦ç§»é™¤è‡¨æ™‚æª”ï¼ˆé¿å…æ®˜ç•™ï¼‰
            if os.path.exists(temp_file_path):
                os.unlink(temp_file_path)

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Document upload error: {e}")
        raise HTTPException(status_code=500, detail=f"Upload failed: {str(e)}")


@router.get("/documents", response_model=List[DocumentResponse])
async def get_documents(
    category: Optional[str] = None,
    skip: int = 0,
    limit: int = 50,
    current_user: dict = Depends(require_roles("admin")),
):
    """
    å–å¾—æ–‡æª”åˆ—è¡¨ï¼ˆåƒ…ç®¡ç†å“¡ï¼‰
    - æ”¯æ´åˆ†é ï¼šskip/limitï¼Œå›æ‡‰ header æœƒé™„åŠ  X-Total-Count / X-Skip / X-Limit
    - å›å‚³æœ¬é«”ä»ç¶­æŒã€Œæ¸…å–®ã€ä»¥ç›¸å®¹èˆŠå‰ç«¯
    """
    try:
        documents = ai_engine.get_documents(category)
        total = len(documents)
        sliced = documents[skip: skip + limit] if limit > 0 else documents[skip:]
        headers = {
            "X-Total-Count": str(total),
            "X-Skip": str(skip),
            "X-Limit": str(limit),
        }
        return JSONResponse(content=sliced, headers=headers)
    except Exception as e:
        logger.error(f"Error getting documents: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/documents/{document_id}")
async def delete_document(
    document_id: int,
    current_user: dict = Depends(require_roles("admin")),
):
    """
    åˆªé™¤æ–‡æª”ï¼ˆåƒ…ç®¡ç†å“¡ï¼‰
    - åƒ…åˆªé™¤è³‡æ–™åº«èˆ‡ç´¢å¼•çš„è©²é …ï¼›å¯¦é«”æª”æ¡ˆç”±æœå‹™å±¤æ±ºå®šæ˜¯å¦ä¿ç•™
    """
    try:
        success = ai_engine.delete_document(document_id)
        if not success:
            raise HTTPException(status_code=404, detail="Document not found")

        logger.info(f"âœ… Document deleted by {_username(current_user)}: {document_id}")
        return {"success": True, "message": "Document deleted successfully"}
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error deleting document: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/documents/{document_id}")
async def get_document_details(
    document_id: int,
    current_user: dict = Depends(require_roles("admin")),
):
    """
    å–å¾—æ–‡æª”è©³ç´°ï¼ˆåƒ…ç®¡ç†å“¡ï¼‰
    - åŒ…å« content_preview / tags / description ç­‰
    """
    try:
        document = ai_engine.get_document_by_id(document_id)
        if not document:
            raise HTTPException(status_code=404, detail="Document not found")
        return {"success": True, **document}
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting document details: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# =============================================================================
# ç¶­é‹ï¼šå‘é‡åº«é‡å»º / å–®æª”å¢é‡
# =============================================================================
@router.post("/reindex")
async def reindex_vector_store(
    current_user: dict = Depends(require_roles("admin")),
):
    """
    ä¸€éµé‡å»º FAISS å‘é‡åº«ï¼ˆä¸å‹•è³‡æ–™è¡¨ï¼‰
    - é©ç”¨ï¼šè®Šæ›´åˆ‡å¡Šç­–ç•¥ / è®Šæ›´å£“ç¸®ç­–ç•¥ / æ¸…ç´¢å¼•å¾Œé‡å»º
    - æœƒä¾è¨­å®šè‡ªå‹•è™•ç† Parent-Childï¼ˆè‹¥å•Ÿç”¨ parent ç‰¹æ€§ï¼‰
    """
    try:
        ai_engine.rag_system.rebuild_vector_store()
        status = ai_engine.get_system_status()
        logger.info(
            f"ğŸ›  é‡æ–°å»ºç«‹å‘é‡åº«å®Œæˆï¼ˆdocs={status.get('total_documents')}, chunks={status.get('total_chunks')}ï¼‰"
        )
        return {
            "success": True,
            "message": "Vector store rebuilt successfully",
            "stats": {
                "total_documents": status.get("total_documents"),
                "total_chunks": status.get("total_chunks"),
                "vector_store_ready": status.get("vector_store_ready"),
                "vector_store_size_bytes": status.get("vector_store_size_bytes"),
                "rag_mode": status.get("rag_mode"),
                "parent_feature": status.get("parent_feature"),
                "hyde": status.get("hyde"),
                "compression": status.get("compression"),
            },
        }
    except Exception as e:
        logger.error(f"Reindex error: {e}")
        raise HTTPException(status_code=500, detail=f"Reindex failed: {str(e)}")


@router.post("/reindex/{document_id}")
async def reindex_single_document(
    document_id: int,
    current_user: dict = Depends(require_roles("admin")),
):
    """
    å–®ä¸€æ–‡ä»¶å¢é‡å…¥ç´¢å¼•ï¼š
      - åªé‡æ–°å‘é‡åŒ–è©²æ–‡ä»¶çš„ chunks
      - è‹¥ç³»çµ±ç‚º parent æ¨¡å¼ï¼ŒæœƒåŒæ­¥åˆ·æ–° parent-child çµæ§‹ï¼ˆç´”è¨˜æ†¶é«”é‡å»ºï¼‰
    """
    try:
        doc = ai_engine.get_document_by_id(document_id)
        if not doc:
            raise HTTPException(status_code=404, detail="Document not found")

        # 1) è¿½åŠ è©²æ–‡ä»¶çš„å‘é‡åˆ†ç‰‡
        ai_engine.rag_system.add_document_chunks(document_id)

        # 2) parent æ¨¡å¼æ™‚ï¼Œé‡å»ºçˆ¶å­ç´¢å¼•ï¼ˆåƒ…é‡å»ºè¨˜æ†¶é«”æ…‹ï¼‰
        status_before = ai_engine.get_system_status()
        if status_before.get("rag_mode") == "parent":
            # æ³¨æ„ï¼šé€™æ˜¯æœå‹™å±¤å…§éƒ¨å®‰å…¨æ–¹æ³•ï¼›ä¸æ“ä½œç£ç¢Ÿï¼Œåƒ…æ›´æ–°æª¢ç´¢çµæ§‹
            ai_engine.rag_system._build_parent_child_indices()

        status_after = ai_engine.get_system_status()
        logger.info(f"ğŸ§© å–®æª”é‡å»ºå®Œæˆï¼š{document_id}")
        return {
            "success": True,
            "message": f"Document {document_id} reindexed",
            "stats": {
                "total_documents": status_after.get("total_documents"),
                "total_chunks": status_after.get("total_chunks"),
                "vector_store_ready": status_after.get("vector_store_ready"),
            },
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Reindex single document error: {e}")
        raise HTTPException(status_code=500, detail=f"Reindex failed: {str(e)}")


# =============================================================================
# æ–‡æª”ä¸‹è¼‰ (æ‰€æœ‰ç™»å…¥ç”¨æˆ¶)
# =============================================================================
@router.get("/documents/{document_id}/download")
async def download_document(
    document_id: int,
    current_user: dict = Depends(get_current_user),
):
    """
    ä¸‹è¼‰æ–‡æª”ï¼ˆæ‰€æœ‰ç™»å…¥ç”¨æˆ¶ï¼‰
    - é€é ai_engine å–å¾—æª”æ¡ˆçš„å¯¦é«”è·¯å¾‘ï¼›è‹¥ä¸å­˜åœ¨å› 404
    - FileResponse é è¨­ä»¥ octet-stream ä¸‹è¼‰
    """
    try:
        document = ai_engine.get_document_by_id(document_id)
        if not document:
            raise HTTPException(status_code=404, detail="Document not found")

        file_path = ai_engine.get_document_path(document_id)
        if not file_path or not file_path.exists():
            raise HTTPException(status_code=404, detail="File not found on server")

        logger.info(f"ğŸ“¥ Document downloaded by {_username(current_user)}: {document['original_name']}")

        return FileResponse(
            path=str(file_path),
            filename=document["original_name"],
            media_type="application/octet-stream",
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error downloading document: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# =============================================================================
# æ–‡æª”æŸ¥è©¢ (æ‰€æœ‰ç™»å…¥ç”¨æˆ¶)
# =============================================================================
@router.post("/query")
async def query_documents(
    req_body: QueryRequest,
    req: Request,
    current_user: dict = Depends(get_current_user),
):
    """
    æŸ¥è©¢æ–‡æª”ï¼ˆRAG + LLMï¼‰
    æµç¨‹ï¼š
      1) æª¢æŸ¥ç³»çµ±ç‹€æ…‹ï¼ˆready / å‘é‡åº«ï¼‰
      2) é¸æ“‡æä¾›å•†ï¼šOpenAIï¼ˆé›²ï¼‰æˆ– Ollamaï¼ˆæœ¬åœ°ï¼‰
      3) å‘¼å« ai_engine.query_documents()
      4) è‹¥å›ç­”ä¸­åŒ…å«ç›¸å°ä¸‹è¼‰è·¯å¾‘ï¼Œè½‰ç‚ºçµ•å° URLï¼ˆé¿å…å‰ç«¯ç›¸å°è·¯å¾‘éŒ¯èª¤ï¼‰
      5) å›æ‡‰ header é€å‡º RAG é…ç½®ï¼Œä¾¿æ–¼é™¤éŒ¯æˆ–ç›£æ§
    """
    try:
        ai_provider = "OpenAI" if req_body.use_openai else "Ollama"
        logger.info(f"ğŸ¤– Processing document query with {ai_provider}: {req_body.question[:100]}...")

        # åŸºç¤å¥åº·ï¼šé¿å…åœ¨ç´¢å¼•æœªå°±ç·’æ™‚è®“ä½¿ç”¨è€…é‡åˆ°ä¸ç©©å®šé«”é©—
        status = ai_engine.get_system_status()
        if status.get("status") != "ready":
            raise HTTPException(status_code=400, detail="Document system not ready. Please contact administrator.")

        # ç„¡è³‡æ–™æ™‚ç›´æ¥å›è¦†ï¼ˆå¯å¼•å°ç®¡ç†å“¡å…ˆä¸Šå‚³æ–‡ä»¶ï¼‰
        if status.get("total_documents", 0) == 0:
            raise HTTPException(status_code=400, detail="No documents available. Please upload documents first.")

        # é¸æ“‡ OpenAI æ™‚éœ€ç¢ºèª OPENAI_API_KEY æ˜¯å¦å·²é…ç½®
        if req_body.use_openai and not status.get("openai_available"):
            raise HTTPException(
                status_code=400,
                detail="OpenAI not available. Please set OPENAI_API_KEY or use Ollama.",
            )

        # å¯¦éš›æŸ¥è©¢ï¼ˆåŒ…å«æª¢ç´¢ã€é‡æ’ã€ç”Ÿæˆ/OA rerank è¦–æœå‹™å±¤é…ç½®ï¼‰
        result = ai_engine.query_documents(req_body.question, req_body.use_openai, req_body.openai_model)

        # çµ±ä¸€éŒ¯èª¤è™•ç†ï¼ˆresult å…§å« status/answer è¨Šæ¯ï¼‰
        if result.get("status") == "error":
            logger.error(f"Query processing error: {result.get('answer')}")
            raise HTTPException(status_code=500, detail=result.get("answer", "Query error"))
        if result.get("status") == "no_documents":
            raise HTTPException(status_code=404, detail=result.get("answer", "No related documents"))

        logger.info(
            f"âœ… Document query processed successfully with {ai_provider} - Type: {result.get('query_type', 'general')}"
        )

        # è½‰æ›ç›¸å°ä¸‹è¼‰é€£çµ â†’ çµ•å° URLï¼ˆAPI Gateway æˆ–å­è·¯å¾‘éƒ¨ç½²æ™‚å°¤å…¶éœ€è¦ï¼‰
        answer = result.get("answer", "")
        if "documents_found" in result or "/api/ai/documents/" in answer:
            base = f"{req.url.scheme}://{req.url.netloc}"
            answer = answer.replace("/api/ai/documents/", f"{base}/api/ai/documents/")

        payload = {
            "success": True,
            "answer": answer,
            "source_documents": result.get("source_documents", []),  # å¯é¸ï¼šç”¨æ–¼å‰ç«¯å±•é–‹è­‰æ“š
            "query_type": result.get("query_type"),
            "ai_provider": result.get("ai_provider"),
            "user": _username(current_user),
        }

        # å›æ‡‰é ­é™„å¸¶ RAG é…ç½®ï¼ˆä¸å½±éŸ¿ JSON æœ¬é«”ï¼‰
        headers = {
            "X-AI-Provider": payload["ai_provider"] or "",
            "X-RAG-Mode": str(status.get("rag_mode", "")),
            "X-RAG-HyDE": "1" if status.get("hyde") else "0",
            "X-RAG-Compression": "1" if status.get("compression") else "0",
        }
        return JSONResponse(content=payload, headers=headers)

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Unexpected error in document query: {e}")
        raise HTTPException(status_code=500, detail=f"Query failed: {str(e)}")


# =============================================================================
# å…¬é–‹ï¼ˆåŸºæœ¬ï¼‰æ–‡æª”åˆ—è¡¨ (æ‰€æœ‰ç™»å…¥ç”¨æˆ¶ï¼Œä¸å«å®Œæ•´å…§å®¹)
# =============================================================================
@router.get("/documents/public/list")
async def get_public_documents(
    category: Optional[str] = None,
    skip: int = 0,
    limit: int = 50,
    current_user: dict = Depends(get_current_user),
):
    """
    å–å¾—å…¬é–‹æ–‡æª”ï¼ˆæ‰€æœ‰ç™»å…¥ç”¨æˆ¶ï¼‰
    - åƒ…å›å¿…è¦æ¬„ä½ & content_previewï¼ˆæœ€å¤š 200 å­—ï¼‰
    - æ”¯æ´åˆ†é ï¼›ä¿ç•™ total/returned/skip/limit ä»¥åˆ©å‰ç«¯åˆ†é  UI
    """
    try:
        documents = ai_engine.get_documents(category)
        sliced = documents[skip: skip + limit] if limit > 0 else documents[skip:]

        public_docs = []
        for doc in sliced:
            preview = doc.get("content_preview") or ""
            public_docs.append({
                "id": doc["id"],
                "original_name": doc["original_name"],
                "category": doc["category"],
                "file_type": doc["file_type"],
                "upload_date": doc["upload_date"],
                "tags": doc.get("tags"),
                "description": doc.get("description"),
                "content_preview": (preview[:200] + "...") if len(preview) > 200 else preview,
            })

        return {
            "success": True,
            "documents": public_docs,
            "total": len(documents),
            "returned": len(public_docs),
            "skip": skip,
            "limit": limit,
            "categories": DOCUMENT_CATEGORIES,
        }
    except Exception as e:
        logger.error(f"Error getting public documents: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# =============================================================================
# AI æä¾›å•†æ¸¬è©¦ï¼ˆåƒ…ç®¡ç†å“¡ï¼‰
# =============================================================================
@router.post("/test-openai")
async def test_openai_connection(
    current_user: dict = Depends(require_roles("admin")),
):
    """
    åµæ¸¬ OpenAI é€£é€šæ€§ï¼š
      - ç›´æ¥å‘¼å«æœå‹™å±¤ openai_generate() ä¸¦è¦æ±‚å›ºå®šå­—ä¸²
      - è‹¥ç’°å¢ƒæœªè¨­ OPENAI_API_KEY æœƒåœ¨æœå‹™å±¤æ‹‹éŒ¯
    """
    try:
        from services.ai_service import openai_generate

        test_response = openai_generate(
            "Please respond with exactly: 'OpenAI connection successful for document analysis'",
            "gpt-4o-mini",
        )
        return {
            "success": True,
            "status": "connected",
            "provider": "openai",
            "model": "gpt-4o-mini",
            "response": test_response,
        }
    except Exception as e:
        logger.error(f"OpenAI test failed: {e}")
        return {"success": False, "status": "failed", "provider": "openai", "error": str(e)}


@router.post("/test-ollama")
async def test_ollama_connection(
    current_user: dict = Depends(require_roles("admin")),
):
    """
    åµæ¸¬ Ollama é€£é€šæ€§ï¼ˆæœ¬åœ° LLMï¼‰ï¼š
      - ç›´æ¥å‘¼å«æœå‹™å±¤ ollama_generate() ä¸¦è¦æ±‚å›ºå®šå­—ä¸²
      - è‹¥ä¸»æ©Ÿæœªæœ‰è©²æ¨¡å‹æœƒå›éŒ¯èª¤ï¼ˆè«‹å…ˆåœ¨ä¸»æ©Ÿ pull æ¨¡å‹ï¼‰
    """
    try:
        from services.ai_service import ollama_generate

        test_response = ollama_generate(
            "Please respond with exactly: 'Ollama connection successful for document analysis'",
            DEFAULT_OLLAMA_MODEL,
        )
        return {
            "success": True,
            "status": "connected",
            "provider": "ollama",
            "model": DEFAULT_OLLAMA_MODEL,
            "response": test_response,
        }
    except Exception as e:
        logger.error(f"Ollama test failed: {e}")
        return {"success": False, "status": "failed", "provider": "ollama", "error": str(e)}


# =============================================================================
# å¸¸è¦‹æŸ¥è©¢å’Œå¹«åŠ©ï¼ˆéœæ…‹å»ºè­°ï¼‰
# =============================================================================
@router.get("/common-queries")
async def get_common_queries():
    """
    å‰ç«¯å¯ç”¨çš„ã€Œå¸¸è¦‹æŸ¥è©¢ã€é¢æ¿ï¼š
      - æ ¹æ“šä½¿ç”¨æƒ…å¢ƒåˆ—å‡ºç¯„ä¾‹å•é¡Œï¼Œé™ä½ä½¿ç”¨é–€æª»
      - äº¦å¯æ ¹æ“šå¯¦éš› SOP/è¡¨å–®å‘½ååšæ›´è²¼åˆçš„æç¤º
    """
    return {
        "success": True,
        "queries": [
            {
                "category": "SOP Inquiries",
                "questions": [
                    "How do I perform quality inspection according to SOP?",
                    "What are the safety procedures for equipment maintenance?",
                    "Can you explain the step-by-step process for [specific procedure]?",
                    "What should I do if I encounter [specific issue] during production?",
                ],
            },
            {
                "category": "Form Assistance",
                "questions": [
                    "How do I fill out the quality inspection form?",
                    "What information is required for the maintenance checklist?",
                    "Can you help me complete the incident report form?",
                    "What are the required fields for [specific form]?",
                ],
            },
            {
                "category": "Document Requests",
                "questions": [
                    "I need the quality inspection form",
                    "Give me the equipment maintenance checklist",
                    "Download the safety procedures document",
                    "Find the production SOP template",
                ],
            },
            {
                "category": "Process Improvement",
                "questions": [
                    "How can we improve the current quality control process?",
                    "What are potential bottlenecks in our production workflow?",
                    "Can you suggest ways to reduce downtime in [specific area]?",
                    "How can we make our documentation more efficient?",
                ],
            },
            {
                "category": "Policy and Compliance",
                "questions": [
                    "What are the current safety regulations?",
                    "How do we ensure compliance with quality standards?",
                    "What documentation is required for audit purposes?",
                    "Can you explain the company policy on [specific topic]?",
                ],
            },
        ],
        "ai_recommendations": {
            "ollama": {
                "description": "é©åˆä¸€èˆ¬ SOP æŸ¥è©¢å’ŒåŸºæœ¬æ–‡æª”åˆ†æ",
                "best_for": ["æ¨™æº–ç¨‹åºæŸ¥è©¢", "è¡¨æ ¼å¡«å¯«æŒ‡å°", "åŸºæœ¬å•é¡Œè§£ç­”"],
            },
            "openai": {
                "description": "é©åˆè¤‡é›œåˆ†æå’Œæ·±åº¦æ”¹é€²å»ºè­°",
                "best_for": ["æµç¨‹æ”¹é€²åˆ†æ", "æ ¹æœ¬åŸå› åˆ†æ", "æˆ°ç•¥æ€§å»ºè­°"],
            },
        },
        "tips": [
            "Be specific about which document or process you're asking about",
            "Use keywords like 'I need', 'Give me', 'Download' to request specific documents",
            "Ask for step-by-step instructions when needed",
            "Request examples or clarifications if something is unclear",
            "Ask about potential improvements or alternative approaches",
        ],
    }


@router.get("/supported-formats")
async def get_supported_formats():
    """
    åˆ—å‡ºæ”¯æ´çš„æª”æ¡ˆæ ¼å¼èˆ‡æ³¨æ„äº‹é …ï¼š
      - åœ–ç‰‡æœƒå…ˆåš OCR è½‰æ–‡å­—å†ç´¢å¼•
      - è¡¨æ ¼æª”ï¼ˆExcel/CSVï¼‰æœƒæŠ½å–è¡¨æ ¼æˆå¯æª¢ç´¢çš„æ–‡å­—é è¦½
      - å…¨æ•¸æ–‡ä»¶çš†æœƒé€² RAG ç´¢å¼•ï¼ˆFAISSï¼‰
    """
    format_descriptions = {
        ".pdf": "PDF documents",
        ".docx": "Microsoft Word documents",
        ".doc": "Legacy Word documents",
        ".txt": "Plain text files",
        ".md": "Markdown files",
        ".xlsx": "Excel spreadsheets",
        ".xls": "Legacy Excel files",
        ".csv": "CSV data files",
        ".png": "PNG images (with OCR)",
        ".jpg": "JPEG images (with OCR)",
        ".jpeg": "JPEG images (with OCR)",
        ".tiff": "TIFF images (with OCR)",
    }

    return {
        "success": True,
        "supported_extensions": sorted(list(SUPPORTED_EXTENSIONS)),
        "format_descriptions": format_descriptions,
        "max_file_size": "50MB",
        "notes": [
            "Images will be processed using OCR to extract text",
            "Excel/CSV files will be converted to textual preview for indexing",
            "All uploaded documents are automatically indexed for RAG search",
            "Use 'I need [document name]' to request specific documents",
        ],
    }
